{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import  numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', is_slippery=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зима пришла. Вы и ваши друзья бросали фрисби в парке, когда вы сделали дикий бросок, который оставил фрисби посреди озера. Вода в основном замерзла, но есть несколько лунок, где лед растаял. Если вы войдете в одну из этих дыр, вы упадете в ледяную воду. В настоящее время существует нехватка международных фрисби, поэтому абсолютно необходимо, чтобы вы пересекли озеро и забрали диск. Однако лед скользкий, поэтому вы не всегда будете двигаться в том направлении, в котором хотите.\n",
    "\n",
    "Эпизод заканчивается, когда вы достигаете цели или падаете в яму. Вы получаете вознаграждение в размере 1, если достигаете цели, и ноль в противном случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "init_state = env.reset()\n",
    "print(init_state)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначения\n",
    "<pre class=\"literal-block\">SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действия:\n",
    "<pre class=\"literal-block\">\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ←\n",
      "1 : ↓\n",
      "2 : →\n",
      "3 : ↑\n"
     ]
    }
   ],
   "source": [
    "action_to_symbol = {\n",
    "    0: '\\u2190',\n",
    "    1: '\\u2193',\n",
    "    2: '\\u2192',\n",
    "    3: '\\u2191'\n",
    "}\n",
    "for a in action_to_symbol.keys():\n",
    "    print(a,':', action_to_symbol[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action= 3\n",
      "next_state, reward, done = 0 0.0 False\n"
     ]
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "print(\"action=\",action)\n",
    "next_state, reward, done, info = env.step(action)\n",
    "print(\"next_state, reward, done =\",next_state, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "init_state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info =env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3333333333333333, 12, 0.0, True), (0.3333333333333333, 9, 0.0, False), (0.3333333333333333, 4, 0.0, False)]\n"
     ]
    }
   ],
   "source": [
    "state = 8\n",
    "action = 2\n",
    "print(env.unwrapped.P[state][action])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre class=\"literal-block\">\n",
    "`is_slippery`: True/False. If True will move in intended direction with\n",
    "probability of 1/3 else will move in either perpendicular direction with\n",
    "equal probability of 1/3 in both directions.\n",
    "    For example, if action is left and is_slippery is True, then:\n",
    "    - P(move left)=1/3\n",
    "    - P(move up)=1/3\n",
    "    - P(move down)=1/3\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP():\n",
    "    def __init__(self, env):\n",
    "        self.states = np.arange(env.observation_space.n)\n",
    "        self.actions = np.arange(env.action_space.n)\n",
    "        self.P = env.unwrapped.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = MDP(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[0 1 2 3]\n",
      "[(0.3333333333333333, 12, 0.0, True), (0.3333333333333333, 9, 0.0, False), (0.3333333333333333, 4, 0.0, False)]\n"
     ]
    }
   ],
   "source": [
    "print(mdp.states)\n",
    "print(mdp.actions)\n",
    "state = 8\n",
    "action = 2\n",
    "print(mdp.P[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.333, 0.333, 0.333], dtype=float32),\n",
       " array([12,  9,  4], dtype=int32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([1., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs, next_states, rewards, dones = zip(*mdp.P[state][action])\n",
    "probs       = np.array(probs, dtype=np.float32)\n",
    "next_states = np.array(next_states, dtype=np.int32)\n",
    "rewards     = np.array(rewards, dtype=np.float32)\n",
    "dones       = np.array(dones, dtype=np.float32)\n",
    "probs, next_states, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.zeros(len(mdp.states), dtype=np.float32)\n",
    "q_value = np.sum(probs*(rewards + (1-dones)*V[next_states]))\n",
    "q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_q_value(transitions, V):\n",
    "    probs, next_states, rewards, dones = zip(*transitions)\n",
    "    probs       = np.array(probs, dtype=np.float32)\n",
    "    next_states = np.array(next_states, dtype=np.int32)\n",
    "    rewards     = np.array(rewards, dtype=np.float32)\n",
    "    dones       = np.array(dones, dtype=np.float32)\n",
    "    q_value = np.sum(probs*(rewards + (1-dones)*V[next_states]))\n",
    "    return q_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DYNAMIC PROGRAMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.333 0.   ]]\n",
      "[[0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.111 0.   ]\n",
      " [0.    0.111 0.444 0.   ]]\n",
      "[[0.    0.    0.    0.   ]\n",
      " [0.    0.    0.037 0.   ]\n",
      " [0.    0.074 0.148 0.   ]\n",
      " [0.    0.185 0.519 0.   ]]\n",
      "[[0.    0.    0.012 0.   ]\n",
      " [0.    0.    0.049 0.   ]\n",
      " [0.025 0.111 0.21  0.   ]\n",
      " [0.    0.259 0.568 0.   ]]\n",
      "[[0.    0.004 0.021 0.004]\n",
      " [0.008 0.    0.074 0.   ]\n",
      " [0.045 0.165 0.243 0.   ]\n",
      " [0.    0.313 0.609 0.   ]]\n",
      "[[0.004 0.008 0.033 0.01 ]\n",
      " [0.018 0.    0.088 0.   ]\n",
      " [0.073 0.2   0.283 0.   ]\n",
      " [0.    0.362 0.641 0.   ]]\n",
      "[[0.01  0.015 0.043 0.017]\n",
      " [0.032 0.    0.105 0.   ]\n",
      " [0.097 0.239 0.31  0.   ]\n",
      " [0.    0.401 0.668 0.   ]]\n",
      "[[0.019 0.023 0.055 0.026]\n",
      " [0.046 0.    0.118 0.   ]\n",
      " [0.123 0.269 0.337 0.   ]\n",
      " [0.    0.436 0.69  0.   ]]\n",
      "[[0.029 0.032 0.066 0.036]\n",
      " [0.063 0.    0.131 0.   ]\n",
      " [0.146 0.299 0.359 0.   ]\n",
      " [0.    0.465 0.708 0.   ]]\n",
      "[[0.041 0.043 0.078 0.046]\n",
      " [0.079 0.    0.142 0.   ]\n",
      " [0.169 0.323 0.379 0.   ]\n",
      " [0.    0.491 0.724 0.   ]]\n",
      "[[0.054 0.054 0.088 0.057]\n",
      " [0.097 0.    0.152 0.   ]\n",
      " [0.191 0.346 0.396 0.   ]\n",
      " [0.    0.513 0.738 0.   ]]\n",
      "[[0.068 0.066 0.099 0.067]\n",
      " [0.114 0.    0.162 0.   ]\n",
      " [0.211 0.367 0.412 0.   ]\n",
      " [0.    0.532 0.75  0.   ]]\n",
      "[[0.084 0.078 0.109 0.078]\n",
      " [0.131 0.    0.17  0.   ]\n",
      " [0.231 0.385 0.426 0.   ]\n",
      " [0.    0.55  0.761 0.   ]]\n",
      "[[0.099 0.09  0.119 0.088]\n",
      " [0.148 0.    0.179 0.   ]\n",
      " [0.249 0.402 0.439 0.   ]\n",
      " [0.    0.565 0.77  0.   ]]\n",
      "[[0.116 0.103 0.129 0.099]\n",
      " [0.166 0.    0.186 0.   ]\n",
      " [0.267 0.418 0.45  0.   ]\n",
      " [0.    0.579 0.779 0.   ]]\n",
      "[[0.132 0.116 0.139 0.109]\n",
      " [0.183 0.    0.193 0.   ]\n",
      " [0.283 0.432 0.461 0.   ]\n",
      " [0.    0.592 0.786 0.   ]]\n",
      "[[0.149 0.129 0.15  0.119]\n",
      " [0.199 0.    0.2   0.   ]\n",
      " [0.299 0.445 0.47  0.   ]\n",
      " [0.    0.603 0.793 0.   ]]\n",
      "[[0.166 0.143 0.16  0.129]\n",
      " [0.216 0.    0.207 0.   ]\n",
      " [0.315 0.458 0.479 0.   ]\n",
      " [0.    0.614 0.799 0.   ]]\n",
      "[[0.183 0.156 0.17  0.139]\n",
      " [0.232 0.    0.213 0.   ]\n",
      " [0.329 0.469 0.488 0.   ]\n",
      " [0.    0.623 0.804 0.   ]]\n",
      "[[0.199 0.169 0.18  0.149]\n",
      " [0.248 0.    0.219 0.   ]\n",
      " [0.344 0.48  0.495 0.   ]\n",
      " [0.    0.632 0.809 0.   ]]\n",
      "[[0.215 0.183 0.189 0.159]\n",
      " [0.264 0.    0.225 0.   ]\n",
      " [0.357 0.49  0.503 0.   ]\n",
      " [0.    0.641 0.814 0.   ]]\n",
      "[[0.232 0.196 0.199 0.169]\n",
      " [0.279 0.    0.231 0.   ]\n",
      " [0.37  0.5   0.51  0.   ]\n",
      " [0.    0.648 0.818 0.   ]]\n",
      "[[0.247 0.209 0.209 0.179]\n",
      " [0.294 0.    0.236 0.   ]\n",
      " [0.383 0.509 0.516 0.   ]\n",
      " [0.    0.656 0.822 0.   ]]\n",
      "[[0.263 0.222 0.218 0.189]\n",
      " [0.308 0.    0.242 0.   ]\n",
      " [0.395 0.518 0.523 0.   ]\n",
      " [0.    0.662 0.826 0.   ]]\n",
      "[[0.278 0.234 0.227 0.199]\n",
      " [0.322 0.    0.247 0.   ]\n",
      " [0.407 0.527 0.529 0.   ]\n",
      " [0.    0.669 0.829 0.   ]]\n",
      "[[0.293 0.246 0.236 0.208]\n",
      " [0.336 0.    0.252 0.   ]\n",
      " [0.419 0.535 0.534 0.   ]\n",
      " [0.    0.675 0.833 0.   ]]\n",
      "[[0.307 0.258 0.245 0.217]\n",
      " [0.349 0.    0.257 0.   ]\n",
      " [0.43  0.543 0.54  0.   ]\n",
      " [0.    0.681 0.836 0.   ]]\n",
      "[[0.321 0.27  0.253 0.226]\n",
      " [0.362 0.    0.262 0.   ]\n",
      " [0.44  0.55  0.545 0.   ]\n",
      " [0.    0.687 0.839 0.   ]]\n",
      "[[0.335 0.281 0.262 0.235]\n",
      " [0.374 0.    0.266 0.   ]\n",
      " [0.451 0.557 0.55  0.   ]\n",
      " [0.    0.692 0.842 0.   ]]\n",
      "[[0.348 0.293 0.27  0.244]\n",
      " [0.387 0.    0.271 0.   ]\n",
      " [0.461 0.564 0.555 0.   ]\n",
      " [0.    0.697 0.845 0.   ]]\n",
      "[[0.361 0.303 0.278 0.253]\n",
      " [0.398 0.    0.275 0.   ]\n",
      " [0.471 0.571 0.56  0.   ]\n",
      " [0.    0.702 0.847 0.   ]]\n",
      "[[0.373 0.314 0.285 0.261]\n",
      " [0.41  0.    0.279 0.   ]\n",
      " [0.48  0.577 0.564 0.   ]\n",
      " [0.    0.707 0.85  0.   ]]\n",
      "[[0.386 0.324 0.293 0.269]\n",
      " [0.421 0.    0.283 0.   ]\n",
      " [0.489 0.584 0.569 0.   ]\n",
      " [0.    0.711 0.852 0.   ]]\n",
      "[[0.397 0.334 0.3   0.277]\n",
      " [0.432 0.    0.287 0.   ]\n",
      " [0.498 0.59  0.573 0.   ]\n",
      " [0.    0.716 0.854 0.   ]]\n",
      "[[0.409 0.344 0.307 0.285]\n",
      " [0.442 0.    0.291 0.   ]\n",
      " [0.507 0.596 0.577 0.   ]\n",
      " [0.    0.72  0.857 0.   ]]\n",
      "[[0.42  0.353 0.314 0.292]\n",
      " [0.453 0.    0.295 0.   ]\n",
      " [0.515 0.601 0.581 0.   ]\n",
      " [0.    0.724 0.859 0.   ]]\n",
      "[[0.431 0.362 0.321 0.299]\n",
      " [0.463 0.    0.298 0.   ]\n",
      " [0.523 0.607 0.585 0.   ]\n",
      " [0.    0.728 0.861 0.   ]]\n",
      "[[0.441 0.371 0.328 0.307]\n",
      " [0.472 0.    0.302 0.   ]\n",
      " [0.531 0.612 0.589 0.   ]\n",
      " [0.    0.732 0.863 0.   ]]\n",
      "[[0.452 0.38  0.335 0.314]\n",
      " [0.481 0.    0.305 0.   ]\n",
      " [0.538 0.617 0.592 0.   ]\n",
      " [0.    0.736 0.865 0.   ]]\n",
      "[[0.462 0.389 0.343 0.321]\n",
      " [0.49  0.    0.309 0.   ]\n",
      " [0.546 0.622 0.596 0.   ]\n",
      " [0.    0.739 0.867 0.   ]]\n",
      "[[0.471 0.398 0.351 0.328]\n",
      " [0.499 0.    0.313 0.   ]\n",
      " [0.553 0.627 0.599 0.   ]\n",
      " [0.    0.743 0.869 0.   ]]\n",
      "[[0.481 0.407 0.359 0.336]\n",
      " [0.508 0.    0.317 0.   ]\n",
      " [0.56  0.632 0.603 0.   ]\n",
      " [0.    0.746 0.87  0.   ]]\n",
      "[[0.49  0.415 0.367 0.343]\n",
      " [0.516 0.    0.321 0.   ]\n",
      " [0.566 0.636 0.606 0.   ]\n",
      " [0.    0.749 0.872 0.   ]]\n",
      "[[0.498 0.424 0.375 0.351]\n",
      " [0.524 0.    0.324 0.   ]\n",
      " [0.573 0.641 0.61  0.   ]\n",
      " [0.    0.753 0.874 0.   ]]\n",
      "[[0.507 0.433 0.384 0.359]\n",
      " [0.532 0.    0.328 0.   ]\n",
      " [0.579 0.645 0.613 0.   ]\n",
      " [0.    0.756 0.875 0.   ]]\n",
      "[[0.515 0.441 0.392 0.367]\n",
      " [0.539 0.    0.332 0.   ]\n",
      " [0.585 0.649 0.616 0.   ]\n",
      " [0.    0.759 0.877 0.   ]]\n",
      "[[0.523 0.449 0.4   0.376]\n",
      " [0.547 0.    0.336 0.   ]\n",
      " [0.591 0.653 0.62  0.   ]\n",
      " [0.    0.762 0.879 0.   ]]\n",
      "[[0.531 0.458 0.408 0.384]\n",
      " [0.554 0.    0.34  0.   ]\n",
      " [0.597 0.657 0.623 0.   ]\n",
      " [0.    0.765 0.88  0.   ]]\n",
      "[[0.539 0.466 0.417 0.392]\n",
      " [0.561 0.    0.344 0.   ]\n",
      " [0.603 0.661 0.626 0.   ]\n",
      " [0.    0.767 0.882 0.   ]]\n",
      "[[0.546 0.474 0.425 0.4  ]\n",
      " [0.567 0.    0.347 0.   ]\n",
      " [0.608 0.665 0.629 0.   ]\n",
      " [0.    0.77  0.883 0.   ]]\n",
      "[[0.553 0.481 0.433 0.408]\n",
      " [0.574 0.    0.351 0.   ]\n",
      " [0.614 0.669 0.632 0.   ]\n",
      " [0.    0.773 0.884 0.   ]]\n",
      "[[0.56  0.489 0.441 0.416]\n",
      " [0.58  0.    0.355 0.   ]\n",
      " [0.619 0.673 0.635 0.   ]\n",
      " [0.    0.775 0.886 0.   ]]\n",
      "[[0.567 0.497 0.449 0.425]\n",
      " [0.586 0.    0.359 0.   ]\n",
      " [0.624 0.676 0.638 0.   ]\n",
      " [0.    0.778 0.887 0.   ]]\n",
      "[[0.573 0.504 0.457 0.433]\n",
      " [0.592 0.    0.362 0.   ]\n",
      " [0.629 0.68  0.641 0.   ]\n",
      " [0.    0.78  0.888 0.   ]]\n",
      "[[0.58  0.511 0.464 0.441]\n",
      " [0.598 0.    0.366 0.   ]\n",
      " [0.634 0.683 0.643 0.   ]\n",
      " [0.    0.783 0.89  0.   ]]\n",
      "[[0.586 0.518 0.472 0.449]\n",
      " [0.604 0.    0.369 0.   ]\n",
      " [0.638 0.687 0.646 0.   ]\n",
      " [0.    0.785 0.891 0.   ]]\n",
      "[[0.592 0.525 0.48  0.456]\n",
      " [0.609 0.    0.373 0.   ]\n",
      " [0.643 0.69  0.649 0.   ]\n",
      " [0.    0.788 0.892 0.   ]]\n",
      "[[0.598 0.532 0.487 0.464]\n",
      " [0.615 0.    0.376 0.   ]\n",
      " [0.647 0.693 0.652 0.   ]\n",
      " [0.    0.79  0.893 0.   ]]\n",
      "[[0.603 0.539 0.495 0.472]\n",
      " [0.62  0.    0.38  0.   ]\n",
      " [0.652 0.696 0.654 0.   ]\n",
      " [0.    0.792 0.894 0.   ]]\n",
      "[[0.609 0.546 0.502 0.479]\n",
      " [0.625 0.    0.383 0.   ]\n",
      " [0.656 0.699 0.657 0.   ]\n",
      " [0.    0.794 0.895 0.   ]]\n",
      "[[0.614 0.552 0.509 0.487]\n",
      " [0.63  0.    0.386 0.   ]\n",
      " [0.66  0.702 0.659 0.   ]\n",
      " [0.    0.796 0.897 0.   ]]\n",
      "[[0.619 0.558 0.516 0.494]\n",
      " [0.635 0.    0.389 0.   ]\n",
      " [0.664 0.705 0.662 0.   ]\n",
      " [0.    0.798 0.898 0.   ]]\n",
      "[[0.625 0.565 0.523 0.502]\n",
      " [0.639 0.    0.393 0.   ]\n",
      " [0.668 0.708 0.664 0.   ]\n",
      " [0.    0.8   0.899 0.   ]]\n",
      "[[0.63  0.571 0.53  0.509]\n",
      " [0.644 0.    0.396 0.   ]\n",
      " [0.672 0.711 0.666 0.   ]\n",
      " [0.    0.802 0.9   0.   ]]\n",
      "[[0.634 0.577 0.536 0.516]\n",
      " [0.648 0.    0.399 0.   ]\n",
      " [0.676 0.714 0.669 0.   ]\n",
      " [0.    0.804 0.901 0.   ]]\n",
      "[[0.639 0.582 0.543 0.523]\n",
      " [0.653 0.    0.402 0.   ]\n",
      " [0.679 0.716 0.671 0.   ]\n",
      " [0.    0.806 0.902 0.   ]]\n",
      "[[0.644 0.588 0.549 0.529]\n",
      " [0.657 0.    0.405 0.   ]\n",
      " [0.683 0.719 0.673 0.   ]\n",
      " [0.    0.808 0.903 0.   ]]\n",
      "[[0.648 0.594 0.556 0.536]\n",
      " [0.661 0.    0.408 0.   ]\n",
      " [0.686 0.721 0.675 0.   ]\n",
      " [0.    0.81  0.904 0.   ]]\n",
      "[[0.652 0.599 0.562 0.543]\n",
      " [0.665 0.    0.41  0.   ]\n",
      " [0.69  0.724 0.677 0.   ]\n",
      " [0.    0.812 0.904 0.   ]]\n",
      "[[0.657 0.604 0.568 0.549]\n",
      " [0.669 0.    0.413 0.   ]\n",
      " [0.693 0.726 0.68  0.   ]\n",
      " [0.    0.813 0.905 0.   ]]\n",
      "[[0.661 0.61  0.574 0.555]\n",
      " [0.673 0.    0.416 0.   ]\n",
      " [0.696 0.729 0.682 0.   ]\n",
      " [0.    0.815 0.906 0.   ]]\n",
      "[[0.665 0.615 0.58  0.561]\n",
      " [0.677 0.    0.418 0.   ]\n",
      " [0.699 0.731 0.684 0.   ]\n",
      " [0.    0.817 0.907 0.   ]]\n",
      "[[0.669 0.62  0.585 0.567]\n",
      " [0.68  0.    0.421 0.   ]\n",
      " [0.702 0.733 0.685 0.   ]\n",
      " [0.    0.818 0.908 0.   ]]\n",
      "[[0.673 0.625 0.591 0.573]\n",
      " [0.684 0.    0.424 0.   ]\n",
      " [0.705 0.735 0.687 0.   ]\n",
      " [0.    0.82  0.909 0.   ]]\n",
      "[[0.676 0.629 0.596 0.579]\n",
      " [0.687 0.    0.426 0.   ]\n",
      " [0.708 0.737 0.689 0.   ]\n",
      " [0.    0.821 0.909 0.   ]]\n",
      "[[0.68  0.634 0.602 0.585]\n",
      " [0.69  0.    0.428 0.   ]\n",
      " [0.711 0.739 0.691 0.   ]\n",
      " [0.    0.823 0.91  0.   ]]\n",
      "[[0.683 0.638 0.607 0.59 ]\n",
      " [0.694 0.    0.431 0.   ]\n",
      " [0.714 0.741 0.693 0.   ]\n",
      " [0.    0.824 0.911 0.   ]]\n",
      "[[0.687 0.643 0.612 0.596]\n",
      " [0.697 0.    0.433 0.   ]\n",
      " [0.716 0.743 0.694 0.   ]\n",
      " [0.    0.826 0.912 0.   ]]\n",
      "[[0.69  0.647 0.617 0.601]\n",
      " [0.7   0.    0.435 0.   ]\n",
      " [0.719 0.745 0.696 0.   ]\n",
      " [0.    0.827 0.912 0.   ]]\n",
      "[[0.693 0.651 0.622 0.606]\n",
      " [0.703 0.    0.438 0.   ]\n",
      " [0.721 0.747 0.698 0.   ]\n",
      " [0.    0.828 0.913 0.   ]]\n",
      "[[0.697 0.656 0.627 0.612]\n",
      " [0.706 0.    0.44  0.   ]\n",
      " [0.724 0.749 0.699 0.   ]\n",
      " [0.    0.83  0.914 0.   ]]\n",
      "[[0.7   0.66  0.631 0.617]\n",
      " [0.709 0.    0.442 0.   ]\n",
      " [0.726 0.751 0.701 0.   ]\n",
      " [0.    0.831 0.914 0.   ]]\n",
      "[[0.703 0.664 0.636 0.621]\n",
      " [0.712 0.    0.444 0.   ]\n",
      " [0.729 0.753 0.702 0.   ]\n",
      " [0.    0.832 0.915 0.   ]]\n",
      "[[0.706 0.667 0.64  0.626]\n",
      " [0.714 0.    0.446 0.   ]\n",
      " [0.731 0.754 0.704 0.   ]\n",
      " [0.    0.833 0.916 0.   ]]\n",
      "[[0.709 0.671 0.645 0.631]\n",
      " [0.717 0.    0.448 0.   ]\n",
      " [0.733 0.756 0.705 0.   ]\n",
      " [0.    0.834 0.916 0.   ]]\n",
      "[[0.711 0.675 0.649 0.635]\n",
      " [0.72  0.    0.45  0.   ]\n",
      " [0.735 0.758 0.707 0.   ]\n",
      " [0.    0.836 0.917 0.   ]]\n",
      "[[0.714 0.678 0.653 0.64 ]\n",
      " [0.722 0.    0.452 0.   ]\n",
      " [0.738 0.759 0.708 0.   ]\n",
      " [0.    0.837 0.918 0.   ]]\n",
      "[[0.717 0.682 0.657 0.644]\n",
      " [0.725 0.    0.454 0.   ]\n",
      " [0.74  0.761 0.71  0.   ]\n",
      " [0.    0.838 0.918 0.   ]]\n",
      "[[0.719 0.685 0.661 0.649]\n",
      " [0.727 0.    0.456 0.   ]\n",
      " [0.742 0.762 0.711 0.   ]\n",
      " [0.    0.839 0.919 0.   ]]\n",
      "[[0.722 0.689 0.665 0.653]\n",
      " [0.729 0.    0.457 0.   ]\n",
      " [0.744 0.764 0.712 0.   ]\n",
      " [0.    0.84  0.919 0.   ]]\n",
      "[[0.724 0.692 0.669 0.657]\n",
      " [0.732 0.    0.459 0.   ]\n",
      " [0.746 0.765 0.713 0.   ]\n",
      " [0.    0.841 0.92  0.   ]]\n",
      "[[0.727 0.695 0.672 0.661]\n",
      " [0.734 0.    0.461 0.   ]\n",
      " [0.748 0.767 0.715 0.   ]\n",
      " [0.    0.842 0.92  0.   ]]\n",
      "[[0.729 0.698 0.676 0.665]\n",
      " [0.736 0.    0.462 0.   ]\n",
      " [0.749 0.768 0.716 0.   ]\n",
      " [0.    0.843 0.921 0.   ]]\n",
      "[[0.732 0.701 0.68  0.669]\n",
      " [0.738 0.    0.464 0.   ]\n",
      " [0.751 0.769 0.717 0.   ]\n",
      " [0.    0.844 0.921 0.   ]]\n",
      "[[0.734 0.704 0.683 0.672]\n",
      " [0.74  0.    0.466 0.   ]\n",
      " [0.753 0.771 0.718 0.   ]\n",
      " [0.    0.845 0.922 0.   ]]\n",
      "[[0.736 0.707 0.686 0.676]\n",
      " [0.742 0.    0.467 0.   ]\n",
      " [0.755 0.772 0.719 0.   ]\n",
      " [0.    0.846 0.922 0.   ]]\n",
      "[[0.738 0.71  0.69  0.679]\n",
      " [0.744 0.    0.469 0.   ]\n",
      " [0.756 0.773 0.72  0.   ]\n",
      " [0.    0.847 0.923 0.   ]]\n",
      "[[0.74  0.713 0.693 0.683]\n",
      " [0.746 0.    0.47  0.   ]\n",
      " [0.758 0.774 0.722 0.   ]\n",
      " [0.    0.848 0.923 0.   ]]\n",
      "[[0.742 0.715 0.696 0.686]\n",
      " [0.748 0.    0.472 0.   ]\n",
      " [0.76  0.776 0.723 0.   ]\n",
      " [0.    0.848 0.924 0.   ]]\n",
      "[[0.744 0.718 0.699 0.69 ]\n",
      " [0.75  0.    0.473 0.   ]\n",
      " [0.761 0.777 0.724 0.   ]\n",
      " [0.    0.849 0.924 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "V = np.zeros(len(mdp.states), dtype=np.float64)\n",
    "steps_number = 100\n",
    "for _ in np.arange(steps_number):\n",
    "    V_next  = np.zeros(len(mdp.states), dtype=np.float64)\n",
    "    for s in  mdp.states:\n",
    "        q_values = []\n",
    "        for a in mdp.actions:\n",
    "            q_value = compute_q_value(mdp.P[s][a], V)\n",
    "            q_values.append(q_value)\n",
    "        V_next[s] = np.max(q_values)\n",
    "    V = V_next\n",
    "    print(V.reshape((4,4)))               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALUE ITERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_q_value(transitions, V, gamma):\n",
    "    probs, next_states, rewards, dones = zip(*transitions)\n",
    "    probs       = np.array(probs, dtype=np.float32)\n",
    "    next_states = np.array(next_states, dtype=np.int32)\n",
    "    rewards     = np.array(rewards, dtype=np.float32)\n",
    "    dones       = np.array(dones, dtype=np.float32)\n",
    "    q_value = np.sum(probs*(rewards + gamma*(1-dones)*V[next_states]))\n",
    "    return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "[[0.786 0.779 0.774 0.772]\n",
      " [0.788 0.    0.506 0.   ]\n",
      " [0.793 0.8   0.745 0.   ]\n",
      " [0.    0.864 0.931 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "V = np.zeros(len(mdp.states), dtype=np.float64)\n",
    "epsilon = 1e-10\n",
    "gamma = 0.999\n",
    "#--------------------------------------------------------------------------\n",
    "steps_number = 0\n",
    "while True:\n",
    "    V_next  = np.zeros(len(mdp.states), dtype=np.float64)\n",
    "    for s in  mdp.states:\n",
    "        q_values = []\n",
    "        for a in mdp.actions:\n",
    "            q_value = compute_q_value(mdp.P[s][a], V, gamma)\n",
    "            q_values.append(q_value)\n",
    "        V_next[s] = np.max(q_values)\n",
    "    error = np.max(np.abs(V - V_next))\n",
    "    errors.append(error)\n",
    "    V = V_next\n",
    "    steps_number+=1\n",
    "    if error<=epsilon:\n",
    "        break\n",
    "print(steps_number)\n",
    "print(V.reshape((4,4)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4bb982a9d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.yscale(\"log\") \n",
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение оптимальной стратегии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_fn(mdp, V, gamma):\n",
    "    \"\"\"\n",
    "    return function (state * action-> q_value)\n",
    "    \"\"\"\n",
    "    return lambda state,action: compute_q_value(mdp.P[state][action], V, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(mdp, V, gamma):\n",
    "    \"\"\"\n",
    "    return function (state -> action)\n",
    "    \"\"\"\n",
    "    q_fn  = get_q_fn(mdp, V, gamma)\n",
    "    return lambda state: np.argmax( [q_fn(state, action) for action in mdp.actions])\n",
    "\n",
    "policy = get_policy(mdp, V, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 3, 3],\n",
       "       [0, 0, 0, 0],\n",
       "       [3, 1, 0, 0],\n",
       "       [0, 2, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_actions = np.array([ policy(s) for s in mdp.states  ])\n",
    "best_actions.reshape( (4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Решение:\n",
      "[['←' '↑' '↑' '↑']\n",
      " ['←' '←' '←' '←']\n",
      " ['↑' '↓' '←' '←']\n",
      " ['←' '→' '↓' '←']]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "print('Решение:')\n",
    "print(np.vectorize(action_to_symbol.get)(best_actions.reshape( (4,4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POLICY ITERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_policy_dict = {s: np.random.choice(mdp.actions) for s in mdp.states} \n",
    "init_policy = lambda s: init_policy_dict[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([init_policy(s) for s in mdp.states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(policy, mdp, gamma, epsilon):\n",
    "    V = np.zeros(len(mdp.states), dtype=np.float64)\n",
    "    errors = []\n",
    "    #--------------------------------------------------------------------------\n",
    "    steps_number = 0\n",
    "    while True:\n",
    "        V_next  = np.zeros(len(mdp.states), dtype=np.float64)\n",
    "        for s in  mdp.states:\n",
    "            a = policy(s)\n",
    "            q_value = compute_q_value(mdp.P[s][a], V, gamma)\n",
    "            V_next[s] = q_value\n",
    "        error = np.max(np.abs(V - V_next))\n",
    "        errors.append(error)\n",
    "        V = V_next\n",
    "        steps_number+=1\n",
    "        if error<=epsilon:\n",
    "            break\n",
    "    print(\"Steps=\", steps_number)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(V, mdp, policy):\n",
    "    new_policy = get_policy(mdp, V, gamma)\n",
    "    return new_policy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = policy_eval(policy, mdp, 0.99, 0.1**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_policy_dict = {s: np.random.choice(mdp.actions) for s in mdp.states} \n",
    "init_policy = lambda s: init_policy_dict[s]\n",
    "print([init_policy(s) for s in mdp.states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = init_policy\n",
    "while True:\n",
    "    V = policy_eval(policy, mdp, 0.99, 0.1**10)\n",
    "    new_policy = policy_improvement(V, mdp, policy)\n",
    "    \n",
    "    policy_actions= [policy(s) for s in mdp.states]\n",
    "    new_policy_actions= [new_policy(s) for s in mdp.states]\n",
    "    policy = new_policy\n",
    "    if (policy_actions==new_policy_actions):\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_actions = np.array([ policy(s) for s in mdp.states  ])\n",
    "best_actions.reshape( (4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "print('Решение:')\n",
    "print(np.vectorize(action_to_symbol.get)(best_actions.reshape( (4,4))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gametheory]",
   "language": "python",
   "name": "conda-env-gametheory-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
